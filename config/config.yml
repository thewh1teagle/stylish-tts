training:
  # log training data every this number of steps
  log_interval: 100
  # validate and save model every this number of steps
  save_interval: 5000
  # validate model every this number of steps
  val_interval: 5000
  device: "cuda"
  # Keep this as 'no' if you have the VRAM.
  # Lower precision slows training.
  # "bf16", "fp16", or "no" for no mixed precision
  mixed_precision: "no"

# Number of epochs, max batch sizes and general learning rate of each stage.
training_plan:
  alignment:
    # alignment pretraining
    epochs: 10
    # Maximum number of segments per batch.
    probe_batch_max: 128
    # Learing Rate for this stage
    lr: 1e-5
  acoustic:
    # training of acoustic models and vocoder
    epochs: 5
    probe_batch_max: 16
    lr: 1e-4
  textual:
    # training for duration/pitch/energy from text
    epochs: 5
    probe_batch_max: 32
    lr: 1e-4

dataset:
  train_data: "path/to/your/train-list.txt"
  val_data: "path/to/your/val-list.txt"
  wav_path: "path/to/your/wav-files"
  pitch_path: "path/to/your/pitch.safetensors"
  alignment_path: "path/to/your/alignment.safetensors"

validation:
  # Number of samples to generate per validation step
  sample_count: 10
  # Specific segments to use for validation
  # force_samples:
  # - "filename.from.val_data.txt"
  # - "other.filename.from.val_data.txt"
  # - "other.other.filename.from.val_data.txt"


# Weights are pre-tuned. Do not change these unless you
# know what you are doing.
loss_weight:
  # mel reconstruction loss
  mel: 5
  # generator loss
  generator: 1
  # speech-language model feature matching loss
  slm: 0.2
  # pitch F0 reconstruction loss
  pitch: 3
  # energy reconstruction loss
  energy: 1
  # duration loss
  duration: 1
  # duration predictor probability output cross entropy loss
  duration_ce: 1
  # style reconstruction loss
  style: 1
  # magnitude/phase loss
  magphase: 1
  # confidence for alignment (placeholder)
  confidence: 1
  # alignment loss
  align_loss: 1
  # discriminator loss (placeholder)
  discriminator: 1
